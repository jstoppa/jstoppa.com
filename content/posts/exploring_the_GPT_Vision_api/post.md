---
author: Juan Stoppa
title: Exploring the GPT-4 with Vision API
summary: This article explores the capabilities of the GPT-4 Vision API with an example of each case including more complex scenarios such as object location.
date: 2024-01-08
description: All you need to know to understand the GPT-4 with Vision API.
draft: true
math: true
tags: ["openai", "python", "chatgpt", "gpt-4", "gpt4-vision"]
cover:
    image: "posts/exploring_the_GPT_Vision_api/GPT-4 Vision2.webp"
    caption: GPT-4 with Vision
twitter:
    card: summary_large_image
    site: "@juanstoppa"
    title: Exploring the GPT-4 with Vision API
    description: All you need to know to understand the GPT-4 with Vision API.
---

I've been exploring the GPT-Vision API, at the time of this post the API was in preview mode however it already shoed great advance on what you can do 

## What is GPT-4 with Vision API

GPT-4 Turbo with Vision represents an advanced multimodal model (LMM) created by OpenAI, capable of interpreting images and offering textual answers to queries related to these images. This model blends the capabilities of visual perception with the sophistication of natural language processing.

## The Basic.

The API is used in a similar way as the normal completion api (see ![Getting started with OpenAI in Python](/posts/getting_started_with_openai_in_python/create_v


